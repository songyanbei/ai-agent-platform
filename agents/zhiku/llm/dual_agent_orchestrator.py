"""
ä¸‰æ™ºèƒ½ä½“åè°ƒå™¨
åè°ƒè§„åˆ’æ™ºèƒ½ä½“ã€æ£€ç´¢æ™ºèƒ½ä½“å’Œæ€»ç»“æ™ºèƒ½ä½“çš„å·¥ä½œæµç¨‹
"""
from typing import AsyncGenerator, Dict, Any
import httpx

from agents.zhiku.llm.planning_agent import PlanningAgent
from agents.zhiku.llm.retrieval_agent import RetrievalAgent
from agents.zhiku.llm.summary_agent import SummaryAgent
from agents.zhiku.tools.web_search import TOOL_FUNCTIONS as WEB_TOOL_FUNCTIONS
from config.settings import get_settings
from shared.utils.logger import setup_logger

logger = setup_logger("triple_agent_orchestrator")

# é…ç½®: é€å…¥æ€»ç»“å’Œè¿”å›å‚è€ƒæ–‡çŒ®çš„æœ€å¤§æ–‡æ¡£æ•°
MAX_DOCS_FOR_SUMMARY = 5  # å¯æ ¹æ®éœ€è¦è°ƒæ•´


class DualAgentOrchestrator:
    """
    ä¸‰æ™ºèƒ½ä½“åè°ƒå™¨ (ä¿æŒç±»åå‘åå…¼å®¹)
    
    å·¥ä½œæµç¨‹:
    1. è°ƒç”¨è§„åˆ’æ™ºèƒ½ä½“ â†’ åˆ†æé—®é¢˜å¹¶åˆ¶å®šæ£€ç´¢è®¡åˆ’
    2. è°ƒç”¨æ£€ç´¢æ™ºèƒ½ä½“ â†’ æ‰§è¡Œå¤šåº“æ£€ç´¢å¹¶æ”¶é›†æ–‡æ¡£
    3. è°ƒç”¨æ€»ç»“æ™ºèƒ½ä½“ â†’ ç”Ÿæˆå¸¦å¼•ç”¨çš„æ€»ç»“
    4. è¿”å›å‚è€ƒæ–‡çŒ®åˆ—è¡¨
    """
    
    def __init__(self):
        self.planning_agent = PlanningAgent()
        self.retrieval_agent = RetrievalAgent()
        self.summary_agent = SummaryAgent()
        
        logger.info("ğŸ¯ ä¸‰æ™ºèƒ½ä½“åè°ƒå™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def process(
        self,
        user_query: str
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢
        
        Args:
            user_query: ç”¨æˆ·é—®é¢˜
            
        Yields:
            Dict: äº‹ä»¶æµ
                - {"type": "planning_start"}
                - {"type": "planning_end", "plan": {...}}
                - {"type": "retrieval_start"}
                - {"type": "kb_switch", "kb_id": "...", "kb_name": "..."}
                - {"type": "tool_call_start", ...}
                - {"type": "tool_call_end", ...}
                - {"type": "retrieval_end", "total": N}
                - {"type": "content", "content": "..."}
                - {"type": "references", "references": [...]}
                - {"type": "error", "error": "..."}
        """
        logger.info("=" * 60)
        logger.info(f"ğŸš€ å¼€å§‹å¤„ç†æŸ¥è¯¢: {user_query}")
        logger.info("=" * 60)
        
        try:
            # ========================================
            # é˜¶æ®µ0: è§„åˆ’æ™ºèƒ½ä½“å·¥ä½œ
            # ========================================
            logger.info("ğŸ“ é˜¶æ®µ0: åˆ¶å®šæ£€ç´¢è®¡åˆ’")
            yield {"type": "planning_start"}
            
            # è·å–çŸ¥è¯†åº“é…ç½®
            settings = get_settings()
            knowledge_bases = settings.get_knowledge_bases()
            logger.info(f"å¯ç”¨çŸ¥è¯†åº“: {[kb.name for kb in knowledge_bases]}")
            
            # è°ƒç”¨è§„åˆ’æ™ºèƒ½ä½“
            plan = await self.planning_agent.plan(user_query, knowledge_bases)
            
            # é€šçŸ¥è§„åˆ’å®Œæˆ
            yield {
                "type": "planning_end",
                "plan": plan
            }

            # è®°å½•æ˜¯å¦åŒ…å«ç½‘é¡µæœç´¢è®¡åˆ’
            has_web_search = "web_search_plan" in plan
            if has_web_search:
                logger.info(f"ğŸ“‹ è§„åˆ’åŒ…å«ç½‘é¡µæœç´¢ä»»åŠ¡")

            logger.info(f"âœ… è§„åˆ’å®Œæˆ: {plan.get('analysis', '')}")
            
            # ========================================
            # é˜¶æ®µ1: æ£€ç´¢æ™ºèƒ½ä½“å·¥ä½œ(å¹¶è¡Œæ£€ç´¢)
            # ========================================
            logger.info("ğŸ“ é˜¶æ®µ1: å¹¶è¡Œæ£€ç´¢")
            yield {"type": "retrieval_start"}
            
            # è°ƒç”¨æ£€ç´¢æ™ºèƒ½ä½“(å¹¶è¡Œæ¨¡å¼)
            doc_manager = None
            retrieval_plan = plan.get("retrieval_plan", [])
            
            async for event in self.retrieval_agent.retrieve_with_plan_parallel(retrieval_plan):
                event_type = event.get("type")
                
                if event_type in ["kb_start", "query_start", "query_end", "kb_end"]:
                    # è½¬å‘å¹¶è¡Œæ£€ç´¢äº‹ä»¶
                    yield event
                
                elif event_type == "retrieval_complete":
                    # æ£€ç´¢å®Œæˆ,è·å–æ–‡æ¡£ç®¡ç†å™¨
                    doc_manager = event["doc_manager"]
            
            # æ£€æŸ¥æ˜¯å¦æˆåŠŸè·å–æ–‡æ¡£
            if doc_manager is None:
                yield {
                    "type": "error",
                    "error": "æ£€ç´¢è¿‡ç¨‹æœªè¿”å›æ–‡æ¡£ç®¡ç†å™¨"
                }
                return

            # é€šçŸ¥çŸ¥è¯†åº“æ£€ç´¢å®Œæˆ
            doc_count = len(doc_manager.documents)
            logger.info(f"âœ… çŸ¥è¯†åº“æ£€ç´¢å®Œæˆ,å…± {doc_count} ä¸ªæ–‡æ¡£")

            # ========================================
            # é˜¶æ®µ1.5: ç½‘é¡µæœç´¢ï¼ˆå¦‚æœè§„åˆ’ä¸­åŒ…å«ï¼‰
            # ========================================
            if has_web_search:
                logger.info("ğŸ“ é˜¶æ®µ1.5: æ‰§è¡Œç½‘é¡µæœç´¢")
                yield {"type": "web_search_start"}

                web_search_plan = plan.get("web_search_plan", [])

                for search_item in web_search_plan:
                    queries = search_item.get("queries", [])
                    reason = search_item.get("reason", "")

                    logger.info(f"ğŸ” ç½‘é¡µæœç´¢: {reason}")
                    logger.info(f"   æŸ¥è¯¢åˆ—è¡¨: {queries}")

                    for query in queries:
                        try:
                            # é€šçŸ¥:ç½‘é¡µæœç´¢å¼€å§‹
                            yield {
                                "type": "web_search_query_start",
                                "query": query
                            }

                            # æ‰§è¡Œç½‘é¡µæœç´¢
                            result = await WEB_TOOL_FUNCTIONS["web_search"](query=query, num_results=5)

                            # æ”¶é›†ç½‘é¡µæœç´¢ç»“æœï¼ˆä½œä¸ºæ–‡æ¡£æ·»åŠ åˆ°ç®¡ç†å™¨ï¼‰
                            if result.get("success") and "results" in result:
                                from shared.utils.document_manager import Document

                                for item in result["results"]:
                                    # å°†ç½‘é¡µæœç´¢ç»“æœè½¬æ¢ä¸ºæ–‡æ¡£æ ¼å¼
                                    doc = Document(
                                        content=f"{item.get('title', '')}\n\n{item.get('snippet', '')}",
                                        source=item.get("source", "Web Search"),
                                        knowledge_id=None,  # ç½‘é¡µæœç´¢æ²¡æœ‰çŸ¥è¯†åº“ID
                                        metadata={
                                            "url": item.get("url", ""),
                                            "search_query": query,
                                            "source_type": "web_search"
                                        }
                                    )
                                    doc_manager.add_document(doc)

                                logger.info(f"âœ… ç½‘é¡µæœç´¢ '{query}' è¿”å› {len(result['results'])} ä¸ªç»“æœ")

                            # é€šçŸ¥:ç½‘é¡µæœç´¢ç»“æŸ
                            yield {
                                "type": "web_search_query_end",
                                "query": query,
                                "result": result
                            }

                        except Exception as e:
                            logger.error(f"âŒ ç½‘é¡µæœç´¢ '{query}' å¤±è´¥: {e}")
                            yield {
                                "type": "web_search_query_end",
                                "query": query,
                                "result": {"success": False, "error": str(e)}
                            }

                # æ›´æ–°æ–‡æ¡£æ€»æ•°
                updated_doc_count = len(doc_manager.documents)
                web_search_added = updated_doc_count - doc_count

                logger.info(f"âœ… ç½‘é¡µæœç´¢å®Œæˆ,æ–°å¢ {web_search_added} ä¸ªç»“æœ,æ€»è®¡ {updated_doc_count} ä¸ªæ–‡æ¡£")

                yield {
                    "type": "web_search_end",
                    "added_count": web_search_added,
                    "total": updated_doc_count
                }

                doc_count = updated_doc_count

            # å‘é€æ£€ç´¢å®Œæˆäº‹ä»¶ï¼ˆåŒ…å«çŸ¥è¯†åº“å’Œç½‘é¡µæœç´¢çš„æ€»ç»“æœï¼‰
            yield {
                "type": "retrieval_end",
                "total": doc_count
            }
            
            # å¦‚æœæ²¡æœ‰æ–‡æ¡£,æå‰ç»“æŸ
            if doc_count == 0:
                yield {
                    "type": "content",
                    "content": "æŠ±æ­‰,æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ–‡æ¡£ã€‚è¯·å°è¯•ä½¿ç”¨ä¸åŒçš„å…³é”®è¯é‡æ–°æé—®ã€‚"
                }
                return
            
            # ========================================
            # ç»Ÿä¸€æ–‡æ¡£å¤„ç†:æ’åºå’Œåˆ†ç»„
            # ========================================
            logger.info("ğŸ“ ç»Ÿä¸€æ–‡æ¡£å¤„ç†: æ’åºå’Œå‡†å¤‡å‚è€ƒæ–‡çŒ®")
            
            # 1. å¯¹æ–‡æ¡£æŒ‰ç›¸ä¼¼åº¦æ’åº
            doc_manager.sort_documents(key="score", reverse=True)
            logger.info(f"âœ… æ–‡æ¡£å·²æŒ‰åˆ†æ•°æ’åº")
            
            # 2. æå‰ç”Ÿæˆå‚è€ƒæ–‡çŒ®(è¿™ä¼šæŒ‰doc_idåˆ†ç»„)
            # é™åˆ¶ä¸ºå‰Nä¸ªæ–‡æ¡£
            references = doc_manager.get_references(max_docs=MAX_DOCS_FOR_SUMMARY)
            logger.info(f"âœ… å‚è€ƒæ–‡çŒ®å·²ç”Ÿæˆ: {len(references)} ç¯‡æ–‡ç«  (ä½¿ç”¨å‰{MAX_DOCS_FOR_SUMMARY}ä¸ªæ–‡æ¡£)")
            
            
            # ========================================
            # é˜¶æ®µ2: è¿”å›å‚è€ƒæ–‡çŒ®ï¼ˆåœ¨æ€»ç»“å‰ï¼‰
            # ========================================
            logger.info("ğŸ“ é˜¶æ®µ2: è¿”å›å‚è€ƒæ–‡çŒ®")
            
            # ä½¿ç”¨ä¹‹å‰ç”Ÿæˆçš„å‚è€ƒæ–‡çŒ®(å·²æ’åºå’Œåˆ†ç»„)
            logger.info(f"ğŸ“š è¿”å› {len(references)} æ¡å‚è€ƒæ–‡çŒ®")
            
            yield {
                "type": "references",
                "references": references
            }
            
            # ========================================
            # é˜¶æ®µ3: æ€»ç»“æ™ºèƒ½ä½“å·¥ä½œ
            # ========================================
            logger.info("ğŸ“ é˜¶æ®µ3: ç”Ÿæˆæ€»ç»“")
            
            # è°ƒç”¨æ€»ç»“æ™ºèƒ½ä½“(æµå¼,é™åˆ¶æ–‡æ¡£æ•°é‡)
            async for event in self.summary_agent.summarize(user_query, doc_manager, max_docs=MAX_DOCS_FOR_SUMMARY):
                yield event
            
            logger.info("=" * 60)
            logger.info("ğŸ‰ æŸ¥è¯¢å¤„ç†å®Œæˆ")
            logger.info("=" * 60)
        
        except Exception as e:
            logger.error(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}", exc_info=True)
            yield {
                "type": "error",
                "error": str(e)
            }

