"""
è§„åˆ’æ™ºèƒ½ä½“ - è´Ÿè´£åˆ†æé—®é¢˜å¹¶è§„åˆ’æ£€ç´¢ç­–ç•¥
"""
from openai import AsyncOpenAI
from typing import List, Dict, Any
import json
import httpx
import time

from config.settings import get_settings, KnowledgeBaseConfig
from shared.utils.logger import setup_logger

logger = setup_logger("planning_agent")


class PlanningAgent:
    """
    è§„åˆ’æ™ºèƒ½ä½“
    
    èŒè´£:
    1. åˆ†æç”¨æˆ·é—®é¢˜çš„æ ¸å¿ƒæ„å›¾
    2. æ ¹æ®çŸ¥è¯†åº“æè¿°é€‰æ‹©æœ€ç›¸å…³çš„çŸ¥è¯†åº“(1-Nä¸ª)
    3. ä¸ºæ¯ä¸ªçŸ¥è¯†åº“ç”Ÿæˆä¼˜åŒ–çš„æ£€ç´¢æŸ¥è¯¢
    4. è¾“å‡ºç»“æ„åŒ–çš„æ£€ç´¢è®¡åˆ’
    """
    
    def __init__(self):
        settings = get_settings()
        
        # é…ç½®è¶…æ—¶è®¾ç½®
        timeout = httpx.Timeout(
            connect=60.0,  # è¿æ¥è¶…æ—¶: 60ç§’
            read=300.0,    # è¯»å–è¶…æ—¶: 5åˆ†é’Ÿ
            write=300.0,   # å†™å…¥è¶…æ—¶: 5åˆ†é’Ÿ
            pool=60.0      # è¿æ¥æ± è¶…æ—¶: 60ç§’
        )
        
        # åˆå§‹åŒ– DeepSeek å®¢æˆ·ç«¯
        self.client = AsyncOpenAI(
            api_key=settings.deepseek_api_key,
            base_url=settings.deepseek_base_url,
            timeout=timeout,
            max_retries=3  # æ·»åŠ é‡è¯•æœºåˆ¶
        )
        self.model = settings.deepseek_model
        
        logger.info(f"è§„åˆ’æ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ,æ¨¡å‹: {self.model}")
    
    async def plan(
        self,
        user_query: str,
        knowledge_bases: List[KnowledgeBaseConfig]
    ) -> Dict[str, Any]:
        """
        ä¸ºç”¨æˆ·æŸ¥è¯¢ç”Ÿæˆæ£€ç´¢è®¡åˆ’

        Args:
            user_query: ç”¨æˆ·é—®é¢˜
            knowledge_bases: å¯ç”¨çš„çŸ¥è¯†åº“åˆ—è¡¨

        Returns:
            Dict: æ£€ç´¢è®¡åˆ’,æ ¼å¼:
            {
                "analysis": "ç”¨æˆ·æƒ³äº†è§£...",
                "retrieval_plan": [
                    {
                        "knowledge_base_id": "kb_001",
                        "knowledge_base_name": "é‡‘èç ”æŠ¥åº“",
                        "queries": ["AIé‡‘èåº”ç”¨", "æ™ºèƒ½æŠ•é¡¾"],
                        "reason": "è¯¥åº“åŒ…å«é‡‘èç§‘æŠ€ç›¸å…³ç ”æŠ¥"
                    }
                ],
                "web_search_plan": [
                    {
                        "queries": ["AIé‡‘èåº”ç”¨ æœ€æ–°", "2025å¹´ é‡‘èç§‘æŠ€è¶‹åŠ¿"],
                        "reason": "éœ€è¦è·å–æœ€æ–°èµ„è®¯"
                    }
                ]
            }
        """
        logger.info(f"ğŸ¯ è§„åˆ’æ™ºèƒ½ä½“å¼€å§‹åˆ†æ: {user_query}")
        
        # å¦‚æœåªæœ‰ä¸€ä¸ªçŸ¥è¯†åº“,ç›´æ¥è¿”å›ç®€å•è®¡åˆ’(å‘åå…¼å®¹)
        if len(knowledge_bases) == 1:
            kb = knowledge_bases[0]
            logger.info(f"åªæœ‰ä¸€ä¸ªçŸ¥è¯†åº“,è·³è¿‡è§„åˆ’é˜¶æ®µ: {kb.name}")

            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç½‘é¡µæœç´¢ï¼ˆç®€å•çš„å…³é”®è¯åŒ¹é…ï¼‰
            need_web_search = self._should_use_web_search(user_query)

            plan = {
                "analysis": f"ç”¨æˆ·æŸ¥è¯¢: {user_query}",
                "retrieval_plan": [
                    {
                        "knowledge_base_id": kb.id,
                        "knowledge_base_name": kb.name,
                        "queries": [user_query],  # ç›´æ¥ä½¿ç”¨åŸå§‹æŸ¥è¯¢
                        "reason": "é»˜è®¤çŸ¥è¯†åº“"
                    }
                ]
            }

            # å¦‚æœéœ€è¦ç½‘é¡µæœç´¢ï¼Œæ·»åŠ ç½‘é¡µæœç´¢è®¡åˆ’
            if need_web_search:
                plan["web_search_plan"] = [
                    {
                        "queries": [f"{user_query} æœ€æ–°", f"{user_query} 2025"],
                        "reason": "é—®é¢˜æ¶‰åŠæ—¶æ•ˆæ€§ï¼Œéœ€è¦è·å–æœ€æ–°ä¿¡æ¯"
                    }
                ]

            return plan
        
        # æ„å»ºçŸ¥è¯†åº“æè¿°
        kb_descriptions = []
        for kb in knowledge_bases:
            kb_descriptions.append(
                f"- **{kb.name}** (ID: {kb.id})\n"
                f"  é¢†åŸŸ: {kb.domain}\n"
                f"  æè¿°: {kb.description}"
            )
        kb_info = "\n".join(kb_descriptions)
        
        # è§„åˆ’æç¤ºè¯
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ£€ç´¢è§„åˆ’åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç”¨æˆ·é—®é¢˜,å¹¶åˆ¶å®šæœ€ä¼˜çš„æ£€ç´¢ç­–ç•¥ã€‚

**å¯ç”¨çŸ¥è¯†åº“**:
{kb_info}

**ä½ çš„ä»»åŠ¡**:
1. åˆ†æç”¨æˆ·é—®é¢˜çš„æ ¸å¿ƒæ„å›¾å’Œå…³é”®æ¦‚å¿µ
2. é€‰æ‹©æœ€ç›¸å…³çš„çŸ¥è¯†åº“(1-3ä¸ª,é¿å…å…¨é€‰)
3. ä¸ºæ¯ä¸ªçŸ¥è¯†åº“ç”Ÿæˆ2-3ä¸ªä¼˜åŒ–çš„æ£€ç´¢æŸ¥è¯¢
4. åˆ¤æ–­æ˜¯å¦éœ€è¦ç½‘é¡µæœç´¢æ¥è·å–æœ€æ–°ä¿¡æ¯
5. è¾“å‡ºJSONæ ¼å¼çš„æ£€ç´¢è®¡åˆ’

**ä½•æ—¶ä½¿ç”¨ç½‘é¡µæœç´¢**:
- é—®é¢˜åŒ…å«"æœ€æ–°"ã€"è¿‘æœŸ"ã€"ä»Šå¹´"ã€"æœ€è¿‘"ã€"å½“å‰"ç­‰æ—¶æ•ˆæ€§å…³é”®è¯
- é—®é¢˜æ¶‰åŠæ–°é—»ã€åŠ¨æ€ã€å®æ—¶æ•°æ®
- é—®é¢˜å…³äºæœ€æ–°æŠ€æœ¯è¿›å±•ã€å¸‚åœºè¶‹åŠ¿
- çŸ¥è¯†åº“ä¿¡æ¯å¯èƒ½è¿‡æ—¶ï¼Œéœ€è¦è¡¥å……æœ€æ–°èµ„è®¯

**è¾“å‡ºæ ¼å¼**:
{{
    "analysis": "ç®€è¦åˆ†æç”¨æˆ·é—®é¢˜çš„æ ¸å¿ƒæ„å›¾",
    "retrieval_plan": [
        {{
            "knowledge_base_id": "çŸ¥è¯†åº“ID",
            "knowledge_base_name": "çŸ¥è¯†åº“åç§°",
            "queries": ["æŸ¥è¯¢1", "æŸ¥è¯¢2"],
            "reason": "é€‰æ‹©è¯¥çŸ¥è¯†åº“çš„ç†ç”±"
        }}
    ],
    "web_search_plan": [
        {{
            "queries": ["æœç´¢æŸ¥è¯¢1", "æœç´¢æŸ¥è¯¢2"],
            "reason": "éœ€è¦ç½‘é¡µæœç´¢çš„ç†ç”±"
        }}
    ]
}}

æ³¨æ„:
- `web_search_plan` æ˜¯å¯é€‰çš„ï¼Œåªæœ‰åœ¨ç¡®å®éœ€è¦æ—¶æ‰åŒ…å«
- å¦‚æœä¸éœ€è¦ç½‘é¡µæœç´¢ï¼Œä¸è¦åœ¨è¾“å‡ºä¸­åŒ…å« `web_search_plan` å­—æ®µ

**é‡è¦åŸåˆ™**:
- åªé€‰æ‹©çœŸæ­£ç›¸å…³çš„çŸ¥è¯†åº“,ä¸è¦å…¨é€‰
- æ¯ä¸ªæŸ¥è¯¢åº”ç®€æ´æ˜ç¡®,ä¾¿äºæ£€ç´¢
- ä»ä¸åŒè§’åº¦è®¾è®¡æŸ¥è¯¢,æé«˜è¦†ç›–ç‡
- å¦‚æœé—®é¢˜è·¨é¢†åŸŸ,å¯ä»¥é€‰æ‹©å¤šä¸ªçŸ¥è¯†åº“
- ç½‘é¡µæœç´¢ç”¨äºè·å–çŸ¥è¯†åº“ä¸­å¯èƒ½ç¼ºå¤±çš„æœ€æ–°ä¿¡æ¯

**ç¤ºä¾‹1** (éœ€è¦ç½‘é¡µæœç´¢):
ç”¨æˆ·é—®é¢˜: "äººå·¥æ™ºèƒ½åœ¨é‡‘èé¢†åŸŸçš„æœ€æ–°åº”ç”¨"
è¾“å‡º:
{{
    "analysis": "ç”¨æˆ·æƒ³äº†è§£AIåœ¨é‡‘èé¢†åŸŸçš„æœ€æ–°åº”ç”¨æƒ…å†µï¼Œéœ€è¦ä¸“ä¸šçŸ¥è¯†+æœ€æ–°èµ„è®¯",
    "retrieval_plan": [
        {{
            "knowledge_base_id": "kb_finance",
            "knowledge_base_name": "é‡‘èç ”æŠ¥åº“",
            "queries": ["äººå·¥æ™ºèƒ½ é‡‘èåº”ç”¨", "AIé“¶è¡Œ", "æ™ºèƒ½æŠ•é¡¾"],
            "reason": "è¯¥åº“åŒ…å«é‡‘èè¡Œä¸šçš„AIåº”ç”¨æ¡ˆä¾‹å’Œè¶‹åŠ¿åˆ†æ"
        }}
    ],
    "web_search_plan": [
        {{
            "queries": ["äººå·¥æ™ºèƒ½ é‡‘è æœ€æ–°åº”ç”¨ 2025", "AI é‡‘èç§‘æŠ€ æœ€æ–°è¿›å±•"],
            "reason": "é—®é¢˜è¦æ±‚æœ€æ–°ä¿¡æ¯ï¼Œéœ€è¦æœç´¢æœ€æ–°èµ„è®¯"
        }}
    ]
}}

**ç¤ºä¾‹2** (ä¸éœ€è¦ç½‘é¡µæœç´¢):
ç”¨æˆ·é—®é¢˜: "æ·±åº¦å­¦ä¹ çš„åŸºæœ¬åŸç†"
è¾“å‡º:
{{
    "analysis": "ç”¨æˆ·æƒ³äº†è§£æ·±åº¦å­¦ä¹ çš„åŸºç¡€çŸ¥è¯†ï¼Œè¿™æ˜¯ç»å…¸æŠ€æœ¯ï¼ŒçŸ¥è¯†åº“åº”è¯¥æœ‰è¶³å¤Ÿèµ„æ–™",
    "retrieval_plan": [
        {{
            "knowledge_base_id": "kb_tech",
            "knowledge_base_name": "AIæŠ€æœ¯æ–‡æ¡£åº“",
            "queries": ["æ·±åº¦å­¦ä¹  åŸºæœ¬åŸç†", "ç¥ç»ç½‘ç»œ åŸºç¡€", "æ·±åº¦å­¦ä¹  æ¨¡å‹"],
            "reason": "è¯¥åº“åŒ…å«AIæŠ€æœ¯æ–‡æ¡£å’Œæ•™ç¨‹"
        }}
    ]
}}

è¯·ç›´æ¥è¾“å‡ºJSON,ä¸è¦åŒ…å«å…¶ä»–å†…å®¹ã€‚
 /no_think
"""

        try:
            # è°ƒç”¨ DeepSeek ç”Ÿæˆè§„åˆ’
            start = time.time()
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"è¯·ä¸ºä»¥ä¸‹é—®é¢˜åˆ¶å®šæ£€ç´¢è®¡åˆ’:\n{user_query}"}
                ],
                # temperature=0.3,  # é™ä½æ¸©åº¦,è®©è§„åˆ’æ›´ç¨³å®š
                # response_format={"type": "json_object"}  # å¼ºåˆ¶JSONè¾“å‡º
            )
            
            # è§£æå“åº”
            content = response.choices[0].message.content
            plan = json.loads(content)

            # è®°å½•æ˜¯å¦åŒ…å«ç½‘é¡µæœç´¢è®¡åˆ’
            has_web_search = "web_search_plan" in plan
            logger.info(f"âœ… è§„åˆ’å®Œæˆ,é€‰æ‹©äº† {len(plan.get('retrieval_plan', []))} ä¸ªçŸ¥è¯†åº“, ç½‘é¡µæœç´¢: {has_web_search}")
            logger.debug(f"è§„åˆ’è¯¦æƒ…: {json.dumps(plan, ensure_ascii=False, indent=2)}")
            end = time.time()
            logger.info(end-start)
            return plan
            
        except json.JSONDecodeError as e:
            logger.error(f"âŒ è§£æè§„åˆ’ç»“æœå¤±è´¥: {e}")
            logger.error(f"åŸå§‹å“åº”: {content}")
            # é™çº§æ–¹æ¡ˆ:ä½¿ç”¨æ‰€æœ‰çŸ¥è¯†åº“
            return self._fallback_plan(user_query, knowledge_bases)
        
        except Exception as e:
            logger.error(f"âŒ è§„åˆ’è¿‡ç¨‹å‡ºé”™: {e}", exc_info=True)
            # é™çº§æ–¹æ¡ˆ:ä½¿ç”¨æ‰€æœ‰çŸ¥è¯†åº“
            return self._fallback_plan(user_query, knowledge_bases)
    
    def _fallback_plan(
        self, 
        user_query: str, 
        knowledge_bases: List[KnowledgeBaseConfig]
    ) -> Dict[str, Any]:
        """
        é™çº§æ–¹æ¡ˆ:å½“è§„åˆ’å¤±è´¥æ—¶,ä½¿ç”¨æ‰€æœ‰çŸ¥è¯†åº“
        
        Args:
            user_query: ç”¨æˆ·é—®é¢˜
            knowledge_bases: çŸ¥è¯†åº“åˆ—è¡¨
            
        Returns:
            Dict: ç®€å•çš„æ£€ç´¢è®¡åˆ’
        """
        logger.warning("ä½¿ç”¨é™çº§æ–¹æ¡ˆ:æ£€ç´¢æ‰€æœ‰çŸ¥è¯†åº“")
        
        retrieval_plan = []
        for kb in knowledge_bases:
            retrieval_plan.append({
                "knowledge_base_id": kb.id,
                "knowledge_base_name": kb.name,
                "queries": [user_query],  # ç›´æ¥ä½¿ç”¨åŸå§‹æŸ¥è¯¢
                "reason": "é™çº§æ–¹æ¡ˆ"
            })
        
        return {
            "analysis": f"ç”¨æˆ·æŸ¥è¯¢: {user_query}",
            "retrieval_plan": retrieval_plan
        }

    def _should_use_web_search(self, query: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦ä½¿ç”¨ç½‘é¡µæœç´¢ï¼ˆç®€å•å…³é”®è¯åŒ¹é…ï¼‰

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢

        Returns:
            bool: æ˜¯å¦éœ€è¦ç½‘é¡µæœç´¢
        """
        # æ—¶æ•ˆæ€§å…³é”®è¯
        time_keywords = [
            "æœ€æ–°", "è¿‘æœŸ", "ä»Šå¹´", "æœ€è¿‘", "å½“å‰",
            "2024", "2025", "2026",  # å¹´ä»½
            "æ–°é—»", "åŠ¨æ€", "è¶‹åŠ¿", "è¿›å±•"
        ]

        query_lower = query.lower()
        for keyword in time_keywords:
            if keyword in query_lower:
                logger.info(f"æ£€æµ‹åˆ°æ—¶æ•ˆæ€§å…³é”®è¯ '{keyword}'ï¼Œå°†å¯ç”¨ç½‘é¡µæœç´¢")
                return True

        return False
