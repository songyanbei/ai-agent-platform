"""
æ£€ç´¢æ™ºèƒ½ä½“ - è´Ÿè´£åˆ†æé—®é¢˜å¹¶æ‰§è¡Œå¤šè½®æ£€ç´¢
"""
from openai import AsyncOpenAI
from typing import List, Dict, Any
import json
import asyncio
import uuid
import httpx

from config.settings import get_settings
from agents.zhiku.tools.knowledge_retrieval import AVAILABLE_TOOLS as KB_AVAILABLE_TOOLS, TOOL_FUNCTIONS as KB_TOOL_FUNCTIONS
from agents.zhiku.tools.web_search import AVAILABLE_TOOLS as WEB_AVAILABLE_TOOLS, TOOL_FUNCTIONS as WEB_TOOL_FUNCTIONS
from shared.utils.logger import setup_logger
from shared.utils.document_manager import Document, DocumentManager

logger = setup_logger("retrieval_agent")


class RetrievalAgent:
    """
    æ£€ç´¢æ™ºèƒ½ä½“
    
    èŒè´£:
    1. åˆ†æç”¨æˆ·é—®é¢˜
    2. åˆ¤æ–­æ˜¯å¦éœ€è¦æ‹†è§£ä¸ºå¤šä¸ªæ£€ç´¢æŸ¥è¯¢
    3. å¤šæ¬¡è°ƒç”¨ retrieve_knowledge å·¥å…·
    4. æ”¶é›†å¹¶å»é‡æ–‡æ¡£
    5. è¿”å›æ–‡æ¡£åˆ—è¡¨
    """
    
    def __init__(self):
        settings = get_settings()
        
        # é…ç½®è¶…æ—¶è®¾ç½®
        timeout = httpx.Timeout(
            connect=60.0,  # è¿æ¥è¶…æ—¶: 60ç§’
            read=300.0,    # è¯»å–è¶…æ—¶: 5åˆ†é’Ÿ
            write=300.0,   # å†™å…¥è¶…æ—¶: 5åˆ†é’Ÿ
            pool=60.0      # è¿æ¥æ± è¶…æ—¶: 60ç§’
        )
        
        # åˆå§‹åŒ– DeepSeek å®¢æˆ·ç«¯
        self.client = AsyncOpenAI(
            api_key=settings.deepseek_api_key,
            base_url=settings.deepseek_base_url,
            timeout=timeout,
            max_retries=3  # æ·»åŠ é‡è¯•æœºåˆ¶
        )
        self.model = settings.deepseek_model
        
        # æ³¨å†Œå·¥å…·ï¼ˆåˆå¹¶çŸ¥è¯†åº“æ£€ç´¢å’Œç½‘é¡µæœç´¢ï¼‰
        self.tools = KB_AVAILABLE_TOOLS + WEB_AVAILABLE_TOOLS
        self.tool_functions = {**KB_TOOL_FUNCTIONS, **WEB_TOOL_FUNCTIONS}
        
        # æ–‡æ¡£ç®¡ç†å™¨
        self.doc_manager = DocumentManager()
        
        logger.info(f"æ£€ç´¢æ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ,æ¨¡å‹: {self.model}")
    
    async def retrieve(self, user_query: str, max_iterations: int = 5):
        """
        æ‰§è¡Œæ£€ç´¢ä»»åŠ¡
        
        Args:
            user_query: ç”¨æˆ·é—®é¢˜
            max_iterations: æœ€å¤§å·¥å…·è°ƒç”¨è½®æ•°
            
        Yields:
            Dict: äº‹ä»¶
                - {"type": "tool_call_start", "tool": "retrieve_knowledge", "arguments": {...}}
                - {"type": "tool_call_end", "tool": "retrieve_knowledge", "result": {...}}
                - {"type": "retrieval_complete", "doc_manager": DocumentManager}
        """
        logger.info(f"ğŸ” æ£€ç´¢æ™ºèƒ½ä½“å¼€å§‹å·¥ä½œ: {user_query}")
        
        # ä¸“é—¨çš„æ£€ç´¢æç¤ºè¯
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ£€ç´¢åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä¸ºç”¨æˆ·é—®é¢˜æ‰¾åˆ°æœ€ç›¸å…³çš„æ–‡æ¡£å’Œæœ€æ–°ä¿¡æ¯ã€‚

**æ ¸å¿ƒä»»åŠ¡**:
- åˆ†æç”¨æˆ·é—®é¢˜,æå–æ ¸å¿ƒæ¦‚å¿µ
- æ ¹æ®é—®é¢˜ç±»å‹é€‰æ‹©åˆé€‚çš„æ£€ç´¢æ–¹å¼

**æ£€ç´¢ç­–ç•¥**:

1. **çŸ¥è¯†åº“æ£€ç´¢** (retrieve_knowledge):
   - ç”¨äºæŸ¥æ‰¾ä¸“ä¸šçŸ¥è¯†ã€ç ”æŠ¥æ•°æ®ã€æŠ€æœ¯æ–‡æ¡£
   - é€‚åˆéœ€è¦å¼•ç”¨æƒå¨æ¥æºçš„åœºæ™¯
   - å»ºè®®è°ƒç”¨ 2-3 æ¬¡,ä½¿ç”¨ä¸åŒå…³é”®è¯

2. **ç½‘é¡µæœç´¢** (web_search):
   - ç”¨äºè·å–æœ€æ–°æ–°é—»ã€åŠ¨æ€æˆ–å®æ—¶ä¿¡æ¯
   - å½“çŸ¥è¯†åº“ä¿¡æ¯è¿‡æ—¶æˆ–ä¸è¶³æ—¶è¡¥å……
   - é€‚åˆæŸ¥æ‰¾æœ€æ–°èµ„è®¯ã€å…¬å¼€èµ„æ–™

**ä½¿ç”¨å»ºè®®**:
- å¦‚æœé—®é¢˜æ¶‰åŠæ—¶æ•ˆæ€§ï¼ˆå¦‚"æœ€æ–°"ã€"è¿‘æœŸ"ã€"ä»Šå¹´"ï¼‰ï¼Œä¼˜å…ˆä½¿ç”¨ web_search
- å¦‚æœé—®é¢˜éœ€è¦ä¸“ä¸šçŸ¥è¯†æˆ–å†å²æ•°æ®ï¼Œä¼˜å…ˆä½¿ç”¨ retrieve_knowledge
- å¯ä»¥ç»„åˆä½¿ç”¨ä¸¤ç§å·¥å…·ï¼Œå…ˆæœç´¢çŸ¥è¯†åº“ï¼Œå†è¡¥å……æœ€æ–°ä¿¡æ¯
- æ¯æ¬¡ä½¿ç”¨ä¸åŒçš„å…³é”®è¯ç»„åˆï¼Œé¿å…é‡å¤

**ç¤ºä¾‹**:
ç”¨æˆ·é—®"äººå·¥æ™ºèƒ½åœ¨é‡‘èé¢†åŸŸçš„æœ€æ–°åº”ç”¨"
- è°ƒç”¨1: retrieve_knowledge(query="äººå·¥æ™ºèƒ½ é‡‘èåº”ç”¨", top_k=5)
- è°ƒç”¨2: web_search(query="äººå·¥æ™ºèƒ½ é‡‘è æœ€æ–°åº”ç”¨ 2025", num_results=5)
- è°ƒç”¨3: retrieve_knowledge(query="AI é“¶è¡Œ é£æ§ æ™ºèƒ½æŠ•é¡¾", top_k=5)

**é‡è¦**:
- æ£€ç´¢å®Œæˆå,ç›´æ¥åœæ­¢(ä¸éœ€è¦ç”Ÿæˆç­”æ¡ˆ)
- å……åˆ†åˆ©ç”¨ä¸¤ç§æ£€ç´¢å·¥å…·çš„ä¼˜åŠ¿ï¼Œä¸ºç”¨æˆ·æä¾›å…¨é¢ä¿¡æ¯"""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"è¯·ä¸ºä»¥ä¸‹é—®é¢˜è¿›è¡Œå¤šè§’åº¦æ£€ç´¢:{user_query}"}
        ]
        
        iteration = 0
        
        while iteration < max_iterations:
            iteration += 1
            logger.info(f"ğŸ“ æ£€ç´¢ç¬¬ {iteration} è½®")
            
            try:
                # è°ƒç”¨ DeepSeek
                response = await self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    tools=self.tools,
                    stream=False,  # æ£€ç´¢é˜¶æ®µä¸éœ€è¦æµå¼
                    temperature=0.3  # é™ä½æ¸©åº¦,è®©æ£€ç´¢æ›´ç¨³å®š
                )
                
                choice = response.choices[0]
                message = choice.message
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                if not message.tool_calls:
                    logger.info("âœ… æ£€ç´¢æ™ºèƒ½ä½“å®Œæˆæ‰€æœ‰æ£€ç´¢")
                    break
                
                # è®°å½•åŠ©æ‰‹æ¶ˆæ¯
                messages.append({
                    "role": "assistant",
                    "content": message.content,
                    "tool_calls": [
                        {
                            "id": tc.id,
                            "type": "function",
                            "function": {
                                "name": tc.function.name,
                                "arguments": tc.function.arguments
                            }
                        }
                        for tc in message.tool_calls
                    ]
                })
                
                # æ‰§è¡Œå·¥å…·è°ƒç”¨
                for tool_call in message.tool_calls:
                    function_name = tool_call.function.name
                    arguments = json.loads(tool_call.function.arguments)
                    
                    logger.info(f"ğŸ”§ è°ƒç”¨å·¥å…·: {function_name}({json.dumps(arguments, ensure_ascii=False)})")
                    
                    # é€šçŸ¥å‰ç«¯:å·¥å…·è°ƒç”¨å¼€å§‹
                    yield {
                        "type": "tool_call_start",
                        "tool": function_name,
                        "arguments": arguments
                    }
                    
                    # æ‰§è¡Œå·¥å…·
                    if function_name in self.tool_functions:
                        result = await self.tool_functions[function_name](**arguments)
                        
                        # æ”¶é›†æ–‡æ¡£
                        if result.get("success") and "results" in result:
                            for item in result["results"]:
                                doc = Document(
                                    content=item.get("content", ""),
                                    source=item.get("source", "Unknown"),
                                    knowledge_id=item.get("chunk_id"),
                                    metadata={
                                        "score": item.get("score"),
                                        "doc_id": item.get("doc_id"),
                                        "doc_url": item.get("doc_url"),
                                        "knowledge_base_id": item.get("knowledge_base_id"),
                                        "knowledge_base_name": item.get("knowledge_base_name")
                                    }
                                )
                                self.doc_manager.add_document(doc)
                            
                            logger.info(f"âœ… æœ¬æ¬¡æ£€ç´¢åˆ° {len(result['results'])} ä¸ªæ–‡æ¡£,æ€»è®¡: {len(self.doc_manager.documents)}")
                    else:
                        result = {"success": False, "error": f"æœªçŸ¥å·¥å…·: {function_name}"}
                    
                    # é€šçŸ¥å‰ç«¯:å·¥å…·è°ƒç”¨ç»“æŸ
                    yield {
                        "type": "tool_call_end",
                        "tool": function_name,
                        "result": result
                    }
                    
                    # æ·»åŠ å·¥å…·ç»“æœåˆ°æ¶ˆæ¯
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": json.dumps(result, ensure_ascii=False)
                    })
                
            except Exception as e:
                logger.error(f"âŒ æ£€ç´¢è¿‡ç¨‹å‡ºé”™: {e}", exc_info=True)
                break
        
        logger.info(f"ğŸ‰ æ£€ç´¢å®Œæˆ,å…±æ”¶é›† {len(self.doc_manager.documents)} ä¸ªå”¯ä¸€æ–‡æ¡£")
        
        # è¿”å›æ–‡æ¡£ç®¡ç†å™¨
        yield {
            "type": "retrieval_complete",
            "doc_manager": self.doc_manager
        }
    
    async def retrieve_with_plan_parallel(
        self, 
        retrieval_plan: List[Dict[str, Any]],
        max_queries_per_kb: int = 3
    ):
        """
        æ ¹æ®è§„åˆ’æ‰§è¡Œå¹¶è¡Œå¤šçŸ¥è¯†åº“æ£€ç´¢
        
        Args:
            retrieval_plan: æ£€ç´¢è®¡åˆ’
            max_queries_per_kb: æ¯ä¸ªçŸ¥è¯†åº“æœ€å¤§æŸ¥è¯¢æ¬¡æ•°
            
        Yields:
            Dict: äº‹ä»¶
                - {"type": "kb_start", "kb_id": "...", "kb_name": "...", "task_id": "..."}
                - {"type": "query_start", "task_id": "...", "query": "...", "kb_name": "..."}
                - {"type": "query_end", "task_id": "...", "success": true, "doc_count": N}
                - {"type": "kb_end", "task_id": "...", "kb_name": "...", "total_docs": N}
                - {"type": "retrieval_complete", "doc_manager": DocumentManager}
        """
        logger.info(f"ğŸ” æ£€ç´¢æ™ºèƒ½ä½“å¼€å§‹å¹¶è¡Œæ£€ç´¢,å…± {len(retrieval_plan)} ä¸ªçŸ¥è¯†åº“")
        
        # ä¸ºæ¯ä¸ªçŸ¥è¯†åº“åˆ›å»ºä»»åŠ¡
        async def collect_kb_events(task_id, kb_id, kb_name, queries):
            """æ”¶é›†å•ä¸ªçŸ¥è¯†åº“çš„æ‰€æœ‰äº‹ä»¶"""
            events = []
            async for event in self._retrieve_kb_async(task_id, kb_id, kb_name, queries):
                events.append(event)
            return events
        
        # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
        all_tasks = []
        for plan_item in retrieval_plan:
            kb_id = plan_item["knowledge_base_id"]
            kb_name = plan_item["knowledge_base_name"]
            queries = plan_item["queries"][:max_queries_per_kb]
            
            # ç”Ÿæˆå”¯ä¸€ä»»åŠ¡ID
            task_id = str(uuid.uuid4())[:8]
            
            # åˆ›å»ºä»»åŠ¡(æ³¨æ„:è¿™é‡Œæ˜¯åç¨‹,ä¸æ˜¯ç”Ÿæˆå™¨)
            task = collect_kb_events(task_id, kb_id, kb_name, queries)
            all_tasks.append(task)
        
        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰çŸ¥è¯†åº“çš„æ£€ç´¢
        logger.info(f"ğŸš€ å¯åŠ¨ {len(all_tasks)} ä¸ªå¹¶è¡Œæ£€ç´¢ä»»åŠ¡")
        
        # ä½¿ç”¨ asyncio.as_completed æ¥å®æ—¶è·å–å®Œæˆçš„ä»»åŠ¡
        for coro in asyncio.as_completed(all_tasks):
            events = await coro
            # æŒ‰é¡ºåºyieldæ‰€æœ‰äº‹ä»¶
            for event in events:
                yield event
        
        logger.info(f"ğŸ‰ å¹¶è¡Œæ£€ç´¢å®Œæˆ,å…±æ”¶é›† {len(self.doc_manager.documents)} ä¸ªå”¯ä¸€æ–‡æ¡£")
        
        # è¿”å›æ–‡æ¡£ç®¡ç†å™¨
        yield {
            "type": "retrieval_complete",
            "doc_manager": self.doc_manager
        }
    
    async def _retrieve_kb_async(
        self,
        task_id: str,
        kb_id: str,
        kb_name: str,
        queries: List[str]
    ):
        """
        å¼‚æ­¥æ£€ç´¢å•ä¸ªçŸ¥è¯†åº“
        
        Args:
            task_id: ä»»åŠ¡ID
            kb_id: çŸ¥è¯†åº“ID
            kb_name: çŸ¥è¯†åº“åç§°
            queries: æŸ¥è¯¢åˆ—è¡¨
            
        Yields:
            Dict: äº‹ä»¶
        """
        logger.info(f"[{task_id}] å¼€å§‹æ£€ç´¢çŸ¥è¯†åº“: {kb_name}")
        
        # é€šçŸ¥:çŸ¥è¯†åº“æ£€ç´¢å¼€å§‹
        yield {
            "type": "kb_start",
            "task_id": task_id,
            "kb_id": kb_id,
            "kb_name": kb_name,
            "query_count": len(queries)
        }
        
        kb_doc_count = 0
        
        for query in queries:
            logger.info(f"[{task_id}] æ‰§è¡ŒæŸ¥è¯¢: {query}")
            
            # é€šçŸ¥:æŸ¥è¯¢å¼€å§‹
            yield {
                "type": "query_start",
                "task_id": task_id,
                "kb_name": kb_name,
                "query": query
            }
            
            try:
                # æ‰§è¡Œæ£€ç´¢
                arguments = {
                    "query": query,
                    "top_k": 5,
                    "knowledge_base_id": kb_id
                }
                
                result = await self.tool_functions["retrieve_knowledge"](**arguments)
                
                # æ”¶é›†æ–‡æ¡£
                doc_count = 0
                doc_metadata = []  # æ”¶é›†æ–‡æ¡£å…ƒæ•°æ®
                if result.get("success") and "results" in result:
                    for item in result["results"]:
                        doc = Document(
                            content=item.get("content", ""),
                            source=item.get("source", "Unknown"),
                            knowledge_id=item.get("chunk_id"),
                            metadata={
                                "score": item.get("score"),
                                "doc_id": item.get("doc_id"),
                                "doc_url": item.get("doc_url"),
                                "knowledge_base_id": item.get("knowledge_base_id"),
                                "knowledge_base_name": item.get("knowledge_base_name")
                            }
                        )
                        self.doc_manager.add_document(doc)
                        doc_count += 1
                        
                        # æ”¶é›†å…ƒæ•°æ®ç”¨äºå‰ç«¯å±•ç¤º
                        doc_metadata.append({
                            "title": item.get("source", "Unknown"),
                            "score": item.get("score", 0),
                            "chunk_id": item.get("chunk_id"),
                            "doc_id": item.get("doc_id")
                        })
                    
                    kb_doc_count += doc_count
                    logger.info(f"[{task_id}] âœ… æœ¬æ¬¡æ£€ç´¢åˆ° {doc_count} ä¸ªæ–‡æ¡£")
                
                # é€šçŸ¥:æŸ¥è¯¢ç»“æŸ
                yield {
                    "type": "query_end",
                    "task_id": task_id,
                    "kb_name": kb_name,
                    "query": query,
                    "success": result.get("success", False),
                    "doc_count": doc_count,
                    "doc_metadata": [
                        {**meta, "file_id": meta.get("doc_id"), "file_name": meta.get("title")} 
                        for meta in doc_metadata
                    ]  # æ·»åŠ æ–‡æ¡£å…ƒæ•°æ®ï¼Œå¹¶æ˜ å°„ file_id å’Œ file_name
                }
                
            except Exception as e:
                logger.error(f"[{task_id}] âŒ æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
                
                # é€šçŸ¥:æŸ¥è¯¢å¤±è´¥
                yield {
                    "type": "query_end",
                    "task_id": task_id,
                    "kb_name": kb_name,
                    "query": query,
                    "success": False,
                    "error": str(e),
                    "doc_count": 0
                }
        
        # é€šçŸ¥:çŸ¥è¯†åº“æ£€ç´¢å®Œæˆ
        logger.info(f"[{task_id}] âœ… çŸ¥è¯†åº“ {kb_name} æ£€ç´¢å®Œæˆ,å…± {kb_doc_count} ä¸ªæ–‡æ¡£")
        yield {
            "type": "kb_end",
            "task_id": task_id,
            "kb_id": kb_id,
            "kb_name": kb_name,
            "total_docs": kb_doc_count
        }
    
    async def retrieve_with_plan(
        self, 
        retrieval_plan: List[Dict[str, Any]],
        max_iterations_per_kb: int = 3
    ):
        """
        æ ¹æ®è§„åˆ’æ‰§è¡Œå¤šçŸ¥è¯†åº“æ£€ç´¢(ä¸²è¡Œç‰ˆæœ¬,ä¿ç•™ç”¨äºå…¼å®¹)
        
        Args:
            retrieval_plan: æ£€ç´¢è®¡åˆ’
            max_iterations_per_kb: æ¯ä¸ªçŸ¥è¯†åº“æœ€å¤§æŸ¥è¯¢æ¬¡æ•°
            
        Yields:
            Dict: äº‹ä»¶
        """
        logger.info(f"ğŸ” æ£€ç´¢æ™ºèƒ½ä½“å¼€å§‹æ‰§è¡Œè§„åˆ’,å…± {len(retrieval_plan)} ä¸ªçŸ¥è¯†åº“")
        
        for plan_item in retrieval_plan:
            kb_id = plan_item["knowledge_base_id"]
            kb_name = plan_item["knowledge_base_name"]
            queries = plan_item["queries"][:max_iterations_per_kb]
            
            logger.info(f"ğŸ“ åˆ‡æ¢åˆ°çŸ¥è¯†åº“: {kb_name} ({kb_id})")
            logger.info(f"   è®¡åˆ’æŸ¥è¯¢: {queries}")
            
            # é€šçŸ¥å‰ç«¯:åˆ‡æ¢çŸ¥è¯†åº“
            yield {
                "type": "kb_switch",
                "kb_id": kb_id,
                "kb_name": kb_name,
                "queries": queries
            }
            
            # æ‰§è¡Œè¯¥çŸ¥è¯†åº“çš„æ‰€æœ‰æŸ¥è¯¢
            for query in queries:
                logger.info(f"ğŸ”§ æ‰§è¡ŒæŸ¥è¯¢: {query}")
                
                # æ„é€ å·¥å…·è°ƒç”¨å‚æ•°
                arguments = {
                    "query": query,
                    "top_k": 5,
                    "knowledge_base_id": kb_id
                }
                
                # é€šçŸ¥å‰ç«¯:å·¥å…·è°ƒç”¨å¼€å§‹
                yield {
                    "type": "tool_call_start",
                    "tool": "retrieve_knowledge",
                    "arguments": arguments
                }
                
                # æ‰§è¡Œæ£€ç´¢
                try:
                    result = await self.tool_functions["retrieve_knowledge"](**arguments)
                    
                    # æ”¶é›†æ–‡æ¡£
                    if result.get("success") and "results" in result:
                        for item in result["results"]:
                            doc = Document(
                                content=item.get("content", ""),
                                source=item.get("source", "Unknown"),
                                knowledge_id=item.get("chunk_id"),
                                metadata={
                                    "score": item.get("score"),
                                    "doc_id": item.get("doc_id"),
                                    "doc_url": item.get("doc_url"),
                                    "knowledge_base_id": item.get("knowledge_base_id"),
                                    "knowledge_base_name": item.get("knowledge_base_name")
                                }
                            )
                            self.doc_manager.add_document(doc)
                        
                        logger.info(f"âœ… æœ¬æ¬¡æ£€ç´¢åˆ° {len(result['results'])} ä¸ªæ–‡æ¡£,æ€»è®¡: {len(self.doc_manager.documents)}")
                    
                    # é€šçŸ¥å‰ç«¯:å·¥å…·è°ƒç”¨ç»“æŸ
                    yield {
                        "type": "tool_call_end",
                        "tool": "retrieve_knowledge",
                        "result": result
                    }
                    
                except Exception as e:
                    logger.error(f"âŒ æ£€ç´¢å‡ºé”™: {e}", exc_info=True)
                    error_result = {"success": False, "error": str(e)}
                    yield {
                        "type": "tool_call_end",
                        "tool": "retrieve_knowledge",
                        "result": error_result
                    }
        
        logger.info(f"ğŸ‰ å¤šåº“æ£€ç´¢å®Œæˆ,å…±æ”¶é›† {len(self.doc_manager.documents)} ä¸ªå”¯ä¸€æ–‡æ¡£")
        
        # è¿”å›æ–‡æ¡£ç®¡ç†å™¨
        yield {
            "type": "retrieval_complete",
            "doc_manager": self.doc_manager
        }
